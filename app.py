# app.py (ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€ ë²„ì „)

# --- 1. ê¸°ë³¸ ë° Firebase ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from flask import Flask, session, send_from_directory, request, jsonify, render_template
from flask_mail import Mail, Message
import base64
import uuid
import os
from datetime import datetime
import traceback # ì˜¤ë¥˜ ì¶”ì ì„ ìœ„í•´ ì¶”ê°€
import firebase_admin
from firebase_admin import credentials, storage, db

# --- 2. ë¶„ì„ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
import numpy as np
import pandas as pd
import cv2
import mediapipe as mp
from keras.models import load_model

from gemini_helper import get_gemini_feedback 

# --- â–¼â–¼â–¼â–¼â–¼ [ì¶”ê°€] ì„ì‹œ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ì„¤ì • â–¼â–¼â–¼â–¼â–¼ ---
import atexit
from urllib.parse import urlparse

# ì‚¬ìš©ìë³„ ì„ì‹œ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•  ì „ì—­ ë”•ì…”ë„ˆë¦¬
user_session_data = {}

# ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë  ìë™ ì •ë¦¬ í•¨ìˆ˜
def cleanup_user_data():
    global user_session_data
    print("\n[Cleanup] ì„œë²„ ì¢…ë£Œ ê°ì§€: ì„ì‹œ ì‚¬ìš©ì ë°ì´í„° ë° Storage íŒŒì¼ ì‚­ì œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    bucket = storage.bucket() 
    
    for session_id, rounds_data in list(user_session_data.items()):
        for round_data in rounds_data:
            photo_url = round_data.get('photo_url')
            print(f"  [Cleanup DEBUG] ì²˜ë¦¬ ì¤‘ì¸ URL: {photo_url}") 

            if photo_url and ("storage.googleapis.com" in photo_url or "firebasestorage.googleapis.com" in photo_url): 
                try:
                    parsed_url = urlparse(photo_url)
                    path_in_url = parsed_url.path 
                    
                    file_path_in_storage = None
                    bucket_name_in_path = '/' + bucket.name
                    
                    if bucket_name_in_path in path_in_url:
                        file_path_in_storage = path_in_url.split(bucket_name_in_path + '/', 1)[1]
                    elif '/o/' in path_in_url: 
                        file_path_in_storage = path_in_url.split('/o/', 1)[1]
                    else:
                        print(f"  [Cleanup DEBUG] Warning: ì˜ˆìƒì¹˜ ëª»í•œ URL í˜•ì‹ - {path_in_url}")
                        file_path_in_storage = None 

                    if file_path_in_storage:
                        file_path_in_storage = file_path_in_storage.replace('%2F', '/')
                        if '?' in file_path_in_storage:
                            file_path_in_storage = file_path_in_storage.split('?', 1)[0]

                    print(f"  [Cleanup DEBUG] íŒŒì‹±ëœ Storage ê²½ë¡œ: {file_path_in_storage}") 
                    
                    if file_path_in_storage:
                        blob = bucket.blob(file_path_in_storage)
                        print(f"  [Cleanup DEBUG] Blob ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¤‘: {blob.name}") 
                        if blob.exists():
                            blob.delete()
                            print(f"  âœ… Storage íŒŒì¼ ì‚­ì œ ì„±ê³µ: {file_path_in_storage}")
                        else:
                            print(f"  â„¹ï¸ Storage íŒŒì¼ ì—†ìŒ (ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ê²½ë¡œ ì˜¤ë¥˜): {file_path_in_storage}")
                    else:
                        print(f"  [Cleanup DEBUG] íŒŒì¼ ê²½ë¡œ íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ë¹„ì–´ìˆìŒ: {photo_url}")

                except Exception as e:
                    print(f"  âŒ Storage íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({photo_url}): {e}")
                    traceback.print_exc() 
            else:
                print(f"  [Cleanup DEBUG] ìœ íš¨í•œ Firebase Storage URLì´ ì•„ë‹˜ ë˜ëŠ” ë¹„ì–´ìˆìŒ (í˜•ì‹ ë¶ˆì¼ì¹˜): {photo_url}") 
        
    user_session_data = {}
    print("[Cleanup] ëª¨ë“  ì„ì‹œ ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì•± ì¢…ë£Œ ì‹œ cleanup_user_data í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ë„ë¡ ë“±ë¡
atexit.register(cleanup_user_data)
# --- â–²â–²â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²â–²â–² ---

# --- 3. Flask ì•± ë° Firebase ì´ˆê¸°í™” ---
app = Flask(__name__)
app.secret_key = 'your-very-secret-key-for-session'

try:
    base_dir = os.path.dirname(os.path.abspath(__file__))
    cred_path = os.path.join(base_dir, "serviceAccountKey.json")
    
    cred = credentials.Certificate(cred_path)
    firebase_admin.initialize_app(cred, {
        'storageBucket': 'smilefit-350ea.firebasestorage.app',
        'databaseURL': 'https://smilefit-350ea-default-rtdb.firebaseio.com/'
    })
    print("âœ… Firebase ì•±ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. 'serviceAccountKey.json' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")


# ==============================================================================
# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ì„ ìƒë‹˜ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
# ==============================================================================
def _load_teacher_au_data_to_memory():
    global _teacher_references_in_memory
    _teacher_references_in_memory = {}
    teachers = ['emma', 'olivia', 'sophia']
    print("\n--- ğŸ’¡ ì„ ìƒë‹˜ ê¸°ì¤€ ë°ì´í„° ë©”ëª¨ë¦¬ ë¡œë“œ ì‹œì‘ ---")
    try:
        csv_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data', 'face_embeddings.csv')
        if not os.path.exists(csv_path):
            print(f"âŒ ì˜¤ë¥˜: '{csv_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        df_embeddings = pd.read_csv(csv_path)
        embedding_cols = [col for col in df_embeddings.columns if col.startswith('embedding_')]
        au_feature_cols = [col for col in df_embeddings.columns if col != 'file_name' and not col.startswith('embedding_')]

        for teacher_id in teachers:
            _teacher_references_in_memory[teacher_id] = []
            teacher_df = df_embeddings[df_embeddings['file_name'].str.contains(teacher_id, na=False)].copy()
            if teacher_df.empty: continue
            
            def extract_round_num(filename):
                try: return int(''.join(filter(str.isdigit, filename.split('.')[0])))
                except: return 0
            
            teacher_df['round_number'] = teacher_df['file_name'].apply(extract_round_num)
            teacher_df = teacher_df[teacher_df['round_number'] > 0].sort_values('round_number')

            for _, row in teacher_df.iterrows():
                au_details = {col: float(row[col]) for col in au_feature_cols}
                _teacher_references_in_memory[teacher_id].append({
                    'teacher_id': teacher_id, 'round_number': int(row['round_number']),
                    'embedding': row[embedding_cols].tolist(), 'au_detail_values': au_details,
                    'image_path_static': f'/static/images/teachers/{teacher_id}/{row["file_name"]}'
                })
            print(f"ğŸ‘ '{teacher_id}' ì„ ìƒë‹˜ ë°ì´í„° {len(teacher_df)}ê°œ ë©”ëª¨ë¦¬ ë¡œë“œ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ì„ ìƒë‹˜ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("--- âœ… ëª¨ë“  ì„ ìƒë‹˜ ê¸°ì¤€ ë°ì´í„° ë©”ëª¨ë¦¬ ë¡œë“œ ì™„ë£Œ ---\n")


# ==============================================================================
# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ AU ë¶„ì„ í•µì‹¬ í•¨ìˆ˜ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
# ==============================================================================
# MediaPipe ë° ëª¨ë¸ ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh
face_mesh_instance = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5)
try:
    encoder_model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static', 'models', 'autoencoder_encoder', 'encoder_model.keras')
    encoder_model = load_model(encoder_model_path)
    print("âœ… Autoencoder ì¸ì½”ë” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
except Exception as e:
    print(f"âŒ Autoencoder ì¸ì½”ë” ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    encoder_model = None
feature_cols = ["AU01", "AU02", "AU04", "AU05", "AU06", "AU07", "AU09", "AU10", "AU11", "AU12", "AU14", "AU15", "AU17", "AU20", "AU23", "AU24", "AU25", "AU26", "AU28", "AU43", "AU01_w", "AU02_w", "AU04_w", "AU05_w", "AU06_w", "AU07_w", "AU09_w", "AU10_w", "AU11_w", "AU12_w", "AU14_w", "AU15_w", "AU17_w", "AU20_w", "AU23_w", "AU24_w", "AU25_w", "AU26_w", "AU28_w", "AU43_w"]
AU_LANDMARKS = {'AU01': [336, 296], 'AU02': [334, 298], 'AU04': [9, 8], 'AU05': [159, 144], 'AU06': [205, 206], 'AU07': [159, 145], 'AU09': [19, 219], 'AU10': [11, 10], 'AU11': [61, 291], 'AU12': [308, 78], 'AU14': [41, 13], 'AU15': [84, 17], 'AU17': [13, 15], 'AU20': [32, 262], 'AU23': [13, 14], 'AU24': [13, 14], 'AU25': [13, 14], 'AU26': [10, 152], 'AU28': [13, 14], 'AU43': [145, 374]}

def extract_normalized_au_features(landmarks):
    au_dict = {}
    if not isinstance(landmarks, np.ndarray) or not landmarks.any(): return {col: 0.0 for col in feature_cols}
    try:
        p_left_eye, p_right_eye = landmarks[133], landmarks[362]
        face_scale_distance = np.linalg.norm(p_left_eye - p_right_eye)
        if face_scale_distance < 1e-6: face_scale_distance = 1.0
    except IndexError: face_scale_distance = 1.0
    for au, indices in AU_LANDMARKS.items():
        if indices[0] < len(landmarks) and indices[1] < len(landmarks):
            p1, p2 = landmarks[indices[0]], landmarks[indices[1]]
            au_dict[au] = np.linalg.norm(p1 - p2)
        else: au_dict[au] = 0.0
    final_au_features = {}
    for au_key in AU_LANDMARKS.keys():
        normalized_value = au_dict.get(au_key, 0.0) / face_scale_distance
        if pd.isna(normalized_value): normalized_value = 0.0
        final_au_features[au_key] = float(f"{normalized_value:.4f}")
        final_au_features[f"{au_key}_w"] = float(f"{normalized_value * 0.8:.4f}")
    return final_au_features

def calculate_similarity_score(embedding1, embedding2):
    if embedding1 is None or embedding2 is None: return 0.0
    distance = np.linalg.norm(np.array(embedding1) - np.array(embedding2))
    k_factor = 0.05
    similarity_score = 100 * np.exp(-k_factor * distance)
    return max(0, similarity_score)

# --- â–¼â–¼â–¼â–¼â–¼ [ìˆ˜ì •ëœ ë¶€ë¶„] ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€ â–¼â–¼â–¼â–¼â–¼ ---
def analyze_user_image(image_bytes, teacher_embedding):
    print("\n[Analyze] 1. ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘")
    if encoder_model is None:
        print("[Analyze] âŒ ì˜¤ë¥˜: Autoencoder ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise Exception("Autoencoder ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        image_np = np.frombuffer(image_bytes, np.uint8)
        image_bgr = cv2.imdecode(image_np, cv2.IMREAD_COLOR)
        if image_bgr is None:
            print("[Analyze] âŒ ì˜¤ë¥˜: ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            raise ValueError("ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print("[Analyze] 2. ì´ë¯¸ì§€ ë””ì½”ë”© ì™„ë£Œ")
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        
        print("[Analyze] 3. MediaPipe ì²˜ë¦¬ ì‹œì‘...")
        results = face_mesh_instance.process(image_rgb)
        print("[Analyze] 4. MediaPipe ì²˜ë¦¬ ì™„ë£Œ") # <-- ë§Œì•½ ì´ ë¡œê·¸ê°€ ì•ˆ ì°íˆë©´ process()ê°€ ë¬¸ì œ!

        if not results.multi_face_landmarks:
            print("[Analyze] 5. ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨")
            return {'status': 'no_face_detected', 'message': 'ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        print("[Analyze] 6. ëœë“œë§ˆí¬ ì¶”ì¶œ ì‹œì‘")
        landmarks_np = np.array([[lm.x, lm.y, lm.z] for lm in results.multi_face_landmarks[0].landmark])
        
        print("[Analyze] 7. AU íŠ¹ì§• ì¶”ì¶œ ì‹œì‘")
        au_features_dict = extract_normalized_au_features(landmarks_np)
        au_features_for_model = np.array([au_features_dict.get(col, 0.0) for col in feature_cols], dtype=np.float32).reshape(1, -1)
        
        print("[Analyze] 8. ì¸ì½”ë” ëª¨ë¸ ì˜ˆì¸¡ ì‹œì‘...")
        user_embedding = encoder_model.predict(au_features_for_model)[0]
        print("[Analyze] 9. ì¸ì½”ë” ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ") # <-- ë§Œì•½ ì´ ë¡œê·¸ê°€ ì•ˆ ì°íˆë©´ predict()ê°€ ë¬¸ì œ!

        score = calculate_similarity_score(user_embedding.tolist(), teacher_embedding)
        print("[Analyze] 10. ë¶„ì„ ìµœì¢… ì™„ë£Œ\n")
        
        return {'status': 'success', 'predicted_score': score, 'user_embedding': user_embedding.tolist(), 'au_features': au_features_dict}
    
    except Exception as e:
        print(f"[Analyze] âŒ ë¶„ì„ í•¨ìˆ˜ ë‚´ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {e}")
        traceback.print_exc()
        # ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŒì„ ì•Œë¦¬ëŠ” ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì—¬ ì„œë²„ê°€ ë©ˆì¶”ì§€ ì•Šë„ë¡ í•¨
        return {'status': 'error', 'message': f'ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}'}
# --- â–²â–²â–²â–²â–² [ìˆ˜ì •ëœ ë¶€ë¶„] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²â–²â–² ---


# ==============================================================================
# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ API ì—”ë“œí¬ì¸íŠ¸ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
# ==============================================================================

@app.route('/submit_au_data_with_image', methods=['POST'])
def submit_au_data_with_image():
    if 'user_session_id' not in session:
        session['user_session_id'] = str(uuid.uuid4())
    user_session_id = session['user_session_id']

    if 'image_data' not in request.files:
        return jsonify({'message': 'ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400

    image_file = request.files['image_data']
    teacher_id = request.form.get('teacher_id')
    round_number = request.form.get('round_number', type=int)

    try:
        teacher_rounds_data = _teacher_references_in_memory.get(teacher_id)
        if not teacher_rounds_data:
            return jsonify({'message': f"'{teacher_id}' ì„ ìƒë‹˜ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        matching_teacher_data = next((item for item in teacher_rounds_data if item["round_number"] == round_number), None)
        if not matching_teacher_data:
            return jsonify({'message': f"ë¼ìš´ë“œ {round_number}ì˜ ê¸°ì¤€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
            
        teacher_embedding = matching_teacher_data.get('embedding')
        
        image_bytes = image_file.read()
        analysis_result = analyze_user_image(image_bytes, teacher_embedding)

        if analysis_result.get('status') != 'success':
            return jsonify(analysis_result), 400

        bucket = storage.bucket()
        filename = f"{user_session_id}_{round_number}_{uuid.uuid4()}.jpg"
        blob = bucket.blob(f"user_images_temp/{teacher_id}/{filename}")
        blob.upload_from_string(image_bytes, content_type='image/jpeg')
        blob.make_public()
        photo_url = blob.public_url

        gemini_feedback = ""

        if user_session_id not in user_session_data:
            user_session_data[user_session_id] = []
        
        data_to_save = {
            'teacher_id': teacher_id, 'round_number': round_number,
            'photo_url': photo_url, 'predicted_score': analysis_result['predicted_score'],
            'au_features': analysis_result['au_features'],
            'user_embedding': analysis_result['user_embedding'],
            'gemini_feedback': gemini_feedback
        }
        user_session_data[user_session_id].append(data_to_save)
        print(f"âœ… ë°ì´í„° ì„ì‹œ ì €ì¥ ì„±ê³µ (ì„¸ì…˜ ID: {user_session_id}, ë¼ìš´ë“œ: {round_number})")

        return jsonify({
            'message': 'ë°ì´í„° ì„ì‹œ ì €ì¥ ì„±ê³µ',
            'predicted_score': analysis_result['predicted_score'],
            'photo_url': photo_url
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'message': f'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {e}'}), 500

@app.route('/get_user_feedback_data', methods=['GET'])
def get_user_feedback_data():
    user_session_id = session.get('user_session_id')
    teacher_id = request.args.get('teacher_id')

    if not user_session_id:
        return jsonify({'message': 'ì„¸ì…˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ìš´ë™ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.'}), 400

    try:
        user_results = user_session_data.get(user_session_id, [])
        teacher_results = _teacher_references_in_memory.get(teacher_id, [])

        updated_user_results = []
        for user_record in user_results:
            if 'gemini_feedback' not in user_record or not user_record['gemini_feedback'] or \
               "í”¼ë“œë°± ìƒì„±ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤" in user_record['gemini_feedback'] or \
               "ì„ ìƒë‹˜ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬" in user_record['gemini_feedback']:

                print(f"[Gemini Lazy Load] ë¼ìš´ë“œ {user_record.get('round_number')}ì— ëŒ€í•œ Gemini í”¼ë“œë°± ìƒì„± ì‹œë„...")

                matching_teacher_data = next((item for item in teacher_results if item["round_number"] == user_record.get('round_number')), None)

                if matching_teacher_data and 'au_detail_values' in matching_teacher_data:
                    try:
                        generated_feedback = get_gemini_feedback(
                            user_record.get('predicted_score', 0.0),
                            user_record.get('au_features', {}),
                            matching_teacher_data['au_detail_values'],
                            feature_cols
                        )
                        user_record['gemini_feedback'] = generated_feedback
                        print(f"[Gemini Lazy Load] ë¼ìš´ë“œ {user_record.get('round_number')} í”¼ë“œë°± ìƒì„± ì™„ë£Œ.")
                    except Exception as e:
                        print(f"[Gemini Lazy Load] ë¼ìš´ë“œ {user_record.get('round_number')} í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                        user_record['gemini_feedback'] = "í”¼ë“œë°± ìƒì„±ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                else:
                    print(f"[Gemini Lazy Load] ë¼ìš´ë“œ {user_record.get('round_number')}ì˜ ì„ ìƒë‹˜ AU ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ í”¼ë“œë°± ìƒì„± ë¶ˆê°€.")
                    user_record['gemini_feedback'] = "ì„ ìƒë‹˜ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            updated_user_results.append(user_record)

        if user_session_id in user_session_data:
            user_session_data[user_session_id] = updated_user_results

        return jsonify({'user_data': updated_user_results, 'teacher_references': teacher_results})
    except Exception as e:
        traceback.print_exc()
        return jsonify({'message': f'ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}'}), 500

# ==============================================================================
# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ê¸°ì¡´ ë¼ìš°íŠ¸ ë° ë©”ì¼ ê¸°ëŠ¥ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
# ==============================================================================
@app.route('/')
def index():
    return render_template('index.html')

@app.route("/tower_defense_game.html")
def tower_defense_game():
    return render_template("tower_defense_game.html")

@app.route('/models/<path:filename>')
def serve_models(filename): return send_from_directory('static/models', filename)
@app.route('/pages/<path:filename>')
def load_page(filename): return send_from_directory('templates/pages', filename)
@app.route('/scripts/<path:filename>')
def serve_script(filename): return send_from_directory('static/scripts', filename)
@app.route('/static/images/<path:filename>')
def serve_image(filename): return send_from_directory('static/images', filename)
@app.route('/static/sounds/<path:filename>')
def serve_sounds(filename): return send_from_directory('static/sounds', filename)
@app.route('/icons/<path:filename>')
def icons(filename): return send_from_directory('static/icons', filename)
@app.route('/manifest.json')
def manifest(): return send_from_directory('static', 'manifest.json')
@app.route('/serviceWorker.js')
def service_worker(): return send_from_directory('static', 'serviceWorker.js')

app.config.update(
    MAIL_SERVER='smtp.gmail.com', MAIL_PORT=587, MAIL_USE_TLS=True,
    MAIL_USERNAME='your_email@gmail.com', MAIL_PASSWORD='your_app_password',
    MAIL_DEFAULT_SENDER='your_email@gmail.com'
)
mail = Mail(app)

@app.route('/send_email', methods=['POST'])
def send_email():
    data = request.json
    email, images = data['email'], data['images']
    msg = Message('SMILE FIT ê²°ê³¼ ì´ë¯¸ì§€', recipients=[email])
    msg.body = "ì²¨ë¶€ëœ ì‚¬ì§„ì€ SMILE FITì—ì„œ ì´¬ì˜ëœ ê²°ê³¼ì…ë‹ˆë‹¤."
    for i, img_data_url in enumerate(images):
        header, base64_data = img_data_url.split(',', 1)
        img_bytes = base64.b64decode(base64_data)
        msg.attach(f'image_{i+1}.png', 'image/png', img_bytes)
    try:
        mail.send(msg)
        return jsonify({'message': 'âœ… ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ!'})
    except Exception as e:
        print("ì´ë©”ì¼ ì „ì†¡ ì˜¤ë¥˜:", e)
        return jsonify({'message': 'âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨'}), 500


# ==============================================================================
# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ì„œë²„ ì‹¤í–‰ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
# ==============================================================================
if __name__ == "__main__":
    _load_teacher_au_data_to_memory()
    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False)